# Fundamental of Database

## ACID

- トランザクションは、クエリの集合体
- 何かを行う一つの単位

### Atomicity

- 原子は分割できない
- トランザクションは全て成功するか、1 つでも失敗したらロールバックされる

### Isolation

- トランザクション中に他の人がコミットしたものの影響を受けるか

#### Isolation Level

- Dirty Read
  - あるトランザクションが処理の最中にストレージに書き込んだ未確定なデータを他のトランザクションが読むこと
  - Read Uncommitted

- Non-repeatable Read
  - 自身が複数回データを読んでいるときに、他の人がコミット(UPDATE)したデータを読むと、タイミングによって異なる値が取得される(その行が対象)
  - Read Committed 以下で起こる
  - 行ロック？

- Phantom Read

  - 他のトランザクションでデータを追加/削除すると、`SELECT *`などとしたときに、タイミングによってレコードが増減する
  - Non Repeatable Read 以下で起こる
  - PostgresではNon repeatable Readで起こらないらしい
  - テーブルロック？

- snapshot
  - トランザクション開始時のスナップショットを取得する

- Serializable
  - 完全にそのトランザクションは分離される
  - 上記のどれも起こらないが、ロックの取り方が厳しいのでデッドロックの要因になったりする

- lost update
  - 更新がかち合って、どちらかの更新がなかったことになること

- 楽観ロック
  - ロックを取得しない
  - 更新時に、他の誰かから変更されたかどうかを調べ、だめだったらロールバックする
- 悲観ロック
  - 行ロック、テーブルロック、ページロック

### Consistency

- データ、インスタンス(パーティションなど)
- 外部キーなどで実現される
  - アプリケーションの仕様として実現することもできる
- AtomicityやIsolationもConsistencyの概念の一つ

#### Consistency in data

- 参照整合性
  - 主キーとか外部キーとかの話

#### Consistency in read

- 結果整合性
  - 分散コンピューティングにおいて高可用性を実現するために用いられる整合性モデル
  - 分散コンピューティングではDBを複数に分割している
  - どちらかが更新されたら一定時間後に同期を取る
  - 一定時間後に同じ状態になれば結果整合性が取れていると言える
    - あくまで理論的なので、保証されないこともある？
  - 1つのDBでは更新は即時反映なので強整合性と呼ばれる

#### Snapshot

- トランザクション中にデータが変更された場合にスナップショットを取得する(tempdbに変更前のデータを格納する)
  - [行バージョン方式](#行バージョン方式)
- ファントムリードまで発生しない
- 変更が競合するような場合には不向き
  - 誰かが変更しても、トランザクション中はそれが見えない
  - ロックが取られない方式なので、他のトランザクションによって値が変更されてもそれに気づかず読めてしまう
- 複数のトランザクションが実行されたとき、同じデータを更新した場合、後のトランザクションはエラーとなりロールバックされる(ノンリピータブルリードは発生しない)

#### Serializable

- 楽観ロック？
- 同時実行性がない

### Durability

- 物理的なDBの耐久性
  - WAL(write ahead log)
  - OS cache
  - Fsync OS
- コミット済みのデータを保証する
  
## DBの内部

- 主キー:Postgresでいうrow_id
  - ちなみにユニークキーというやつもあるが、これは`NULL`許容
    - `NULL`重複を許容するかはDBMSによって変わる
  - また、テーブルに対していくつでも作成できる
  - こいつも作るとインデックスが作成される？

### ページ

- データを格納する物理的なもの(DBMSによって変わるが8KB)
- ページに行が保存されている
- 読み込むときはページごとに読み込んでくる
  - RAMではないので、1個だけを読むということではない
  - パーティションなど

### IO

- 極力少なくしたい

### ヒープ

- 取得してきたページの集まりのデータ構造
- こいつから必要なデータを探すためにインデックスが存在する

### インデックス

- テーブルデータ(ヒープ)とは異なる検索のためのデータ
  - ヒープへのポインタ
- こいつを引っ張ってくる事自体もコストがかかる
- ヒープテーブルに対して一つのインデックスが用いられる事がある(クラスター化インデックス)
  - 主キーはその1つとなりえる
  - Postgresの主キーはそうじゃないらしい
    - 通常はrow_idと呼ばれるシステムで管理されているもの
    - Postgresに置いて主キーはセカンダリキー
- インデックスを作成すると、Insertしたときなどにレコードが適切な順ではいるようになる(主キー)
  - これはこれでコストが掛かっているが、検索時のメリットがこれ以上に大きい
- セカンダリインデックスは、上記と異なり、まずインデックス領域に対して`SELECT *`をする？
  - 結局クラスター化インデックスと異なり、インデックス領域にアクセスしてから実データへアクセスすることになるのでやや遅い
  - Postgresでは自身で作成するものは全てこちらになる

#### クラスター化インデックス

- テーブルに対して1つだけ作成できる
  - 主キーが用いられることが多い
- B-tree構造においてリーフノードには実表データが存在している
  - つまり、実表データがクラスター化インデックスによって並び替えられている

#### 非クラスター化インデックス

- セカンダリインデックス
- テーブルに対して複数作成できる

- クラスター化インデックスが存在していない場合
  - リーフノードへはRIDが存在しており、そこを参照する
    - RIDは実表データの場所の情報(ポインタ)
    - つまり実表データが並び替えられていない

- 非クラスター化インデックスにクラスター化インデックスのキーが存在している場合
  - 非クラスター化インデックスでリーフノードまで行ったらキー参照でクラスター化インデックスのツリーをたどる

#### 付加列インデックス

- 終端のリーフノードに列を追加して、RID参照やキー参照を回避する
- 高速化が見込めるが、内部的にデータの2重持ちになるので容量を圧迫する

### 行指向vs列指向

- インデックスを使わない場合を考える
- おおよそメジャーなDBMSは行指向

#### 行指向

- ページが行ごとに組まれる
- ある条件をもとに探すときに、行のデータを全て取得しながら探すのでコストが高い(ページ単位に取得してくるため)
- ただし、一度見つかればその行のデータはすべて使える
- Read/Writeに最適化されている
- オンライントランザクション処理など

#### 列指向

- ページが列ごとに組まれる
  - 1つのページにはある列の情報が詰め込まれている
- ある列を条件をもとに探し、見つかったらその行数を記録してほかの列を探しに行く
  - `SELECT *`は最悪
  - 同様にWriteは遅い
  - 複数行を扱うときは非効率
- 集計関数の集計はその列だけを見に行くのでめちゃくちゃ効率的
- Writeは遅い
- オンライン分析処理

#### より低レベルのDBMSの仕組み

- DBMSはテーブルから行を読み込むと、その行が存在するページを見つけ、ディスク上にあるファイルとオフセットを特定する
- 上記をOSに問い合わせ、OSはそのキャッシュをチェックし、なかったら読み込みを実施する
- DBMSはバッファプールと呼ばれるメモリプールを割り当て、ディスクから読み込まれたページをバッファプールに置く
  - ここに置かれると、要求された行以外にもページ内のものであればアクセスできるようになる
  - これより、インデックス範囲スキャンによる読み取りが効率的になる
  - 1ページに収まる行数が多ければ多いほど、1回のI/Oで得られる利益は大きくなる
- ユーザーが行を更新すると、データベースはその行を特定し、バッファプールにあるページを引き出して該当業を更新し、ジャーナルエントリ(WAL)をディスクに永続化する
- ページはメモリに残るので、最終的にディスクに書き込まれる前に多くの書き込みを受けることができる(I/Oの回数は少なくなる)
- ページの詰め込み方をどのようにするかは、目的次第
  - 行指向/列指向
  - 読み込むページが少なくなるようにしたい
- ページに詰め込まれるデータは、実際のテーブルデータだけではない、ヘッダーやメタデータのサイズが影響を与えることもある
  - 小さいページと大きいページは一長一短

### インデックス(実践)

- B-tree/LSM
- 使うときは**順番に並べられるもの**を考える
  - なのでuuidとかでインデックスを作るのは意味がない

#### B-tree

- 木構造
- 各ノードはキー値(プライマリキーなど)とデータが存在する行へのポインタを持つ
  - これを持つこともコストになる
- B-treeのノードはページ(ヒープのものとは異なる？)
- 計算量はlog(n)
  - 範囲検索は得意ではない

- 例えばidとnameからなる100万行のテーブルを考えてみる
- 以下のような場合、id列に対してインデックスが張られていれば、検索は高速に行われる(Index Seek)

```SQL
SELECT id FROM test WHERE id = 1000
```

- 以下のような場合、idの検索までは高速だが、インデックス領域からヒープ領域へ検索しに行くので時間がかかる(Index Scan)
- ちなみにもう一回やると早くなる(キャッシュ)

```SQL
SELECT name FROM test WHERE id = 1000
```

- インデックスが貼られていない列で条件検索しようとするとめちゃくちゃ遅い(Table Scan)

- Index Only Scan
- Index Scan
- Bitmap Heap Scan(Postgres)
- Bitmap Index Scan(Postgres)
- Seq table Scan
- Parallel Seq Scan

- `LIKE`検索には使用できない
  - 文字列型にインデックスを張ることはできるが、`LIKE`は索引ではなく処理

#### B+tree

- リーフノードだけにデータを持つ
  - 容量削減
  - キー値はリーフノードと被る
- またそれらはリンクされていることで、前後の値がわかる
  - 範囲検索が効率的にできるようになる
  - うまく行けば、1回のヒープ領域のページのI/Oだけで見つけられる
- ググって出てくるBtreeは基本的にこちらで、ほとんどのDBMSはこちらを使っている
- テーブルサイズ小さい(1ページに収まる)ことがわかっているなら、わざわざインデックスを参照するコストよりも、テーブルスキャンとした方がいいとDBMSが判断する
  - そんなことないなら、統計情報を更新したほうが良いかも

- セカンダリインデックスを称しているときは、リーフノードはプライマリインデックスを指す？

- メモリの問題がある？

##### Index Scan

- 比較演算子について使える
  - ORには使えない
- インデックスを使って検索して、ヒープにデータを見に行く
  - 数が少ないと別に良いが、ヒープを見に行く処理はコストがかかる
  - そのため、この数が多いと別のプランが選択されることもある(Seq Scan)
- ヒープを見に行く回数を減らすには、インデックスに別カラム(non-key column)の情報を含める事もできる
  - ただし、インデックスの容量が増えるので、メモリ容量などと相談する必要がある
  - これは複合インデックスとは異なる
  - 複合インデックスの場合は、順番が重要
  - 例えば`index(a, b)`だったら、まず`a`を検索してから`b`を検索する
  - そのため、検索条件に`b`だけを含めてもインデックスが使用されない

##### Bitmap Heap Scan

- B-treeインデックスとは異なる？
- 検索するカラムのカーディナリティが低い場合に有効
  - インデックスに使用している値が順番ではなく、ランダムの場合、インデックスとテーブルの間を行ったり来たりする？
- レコードの種類に対してビットマップが作成され、条件に対してそのビットマップを参照する
- ヒープ領域へのジャンプが1回になる？
- ORにも使える
- OracleやPostgres限定

#### 実行プラン

- データフェッチ前の時間(ページ0を読む時間)とトータルの時間？
- `ORDER BY`とかすると、データフェッチ前の時間が増える？
- インデックスを参照するのもコストが掛かるので、対象が十分に少ない場合はテーブルスキャンが選択される
  - もとからテーブルの行数が少ない
  - 複数の検索条件が指定されているとき、1つ目のインデックスで十分に対象が絞り込めている
  - 絞り込み結果が多くなるような場合でも使われない
- 統計情報

#### Vacuum

- SQL Serverでいうゴーストレコードの対応みたいな
- 追記型アーキテクチャ
- 例えばある行の更新を行った場合は以下のような動作をする
  - 更新対象のレコードに削除フラグをつける
  - 更新後のデータを追加する
- つまり、大量のデータを更新すると、その分データが残ってしまう
- また、インデックスも残る

- このようなデータが溜まると、ディスク容量が増えたり、共有バッファにゴミデータが増えるためメモリアクセスではなくディスクアクセスが発生してしまう

- 再構成
  - 要するにデフラグ
  - オンラインでもできる
- 再構築
  - 完全に新しくインデックスを作り直す
  - オフラインでしかやれないのが一般的
  - 断片化率が一定場を超えたらこちらが推奨されているらしい

### 大規模DBとなったら

- インデックス
- パーティション
- シャーディング

- 垂直分散
  - サーバー間で主従の関係を作る
- 水平分散(シャーデング)
  - サーバー間は対等

- 垂直分割
  - 列ごとに分割する
  - 例えば、更新頻度が高い列群とそうでないものなど
  - 集約が代替手段
  - 基本的にやらないほうが良い
- 水平分割
  - 行ごとに分ける
  - パーティションが代替手段
  - 基本的にやらないほうが良い

- そもそも大規模になる事自体を考え直したほうが良い

- BASE
  - Basically Available
  - Sodt State
  - Eventual Consistency

- CAP定理
  - Consistency
  - Availability
  - Partition-tolerance
- 同時に全てを満たすことはできないらしい

#### パーティション

- テーブルを分割して、クエリの実行対象を小さくすること
- 水平パーティショニング
  - 行で分割する
- 垂直パーティショニング
  - 列で分割する
  - 列にblobが含まれるような場合に使う
- 範囲、リスト、ハッシュで分割
  - 範囲はログデータ、例えば日時や得点
  - リストは例えば国別
  - ハッシュはIPハッシュなど
- ユーザーはバックエンドでパーティショニングされているかどうかには関与しない
  - 親のテーブル名と子のテーブル名は異なっていてよい
- シャーディングは同様にテーブルを分割するが、DBサーバーが複数存在
  - ユーザーが知ることができる
  - テーブル名は変更できない
  - パーティショニングの方が1台のコンピュータなので、まずはそちらを検討

- パーティションを作るときは`null`でないといけない？
- 作成するときは、親のテーブルに子のテーブル(範囲などを指定したもの)をアタッチする
  - 子の方で、範囲指定などしてどのように分割するかを与える
- 分割したテーブルにインデックスを張るべきか？
  - 実は親で作ると、子にも勝手に作られる(DBMSに依存？)
- `ENABLE PARTITION PRUNING`はOFFにするとパーティショニングの意味がなくなってしまうので注意

- 小さいサイズに分割するため、クエリパフォーマンスが良くなる
- 実行プランに影響
- DBMSがよしなにしてくれるので、バルク操作が楽
- アーカイブ？

- データを追加したりするとき、行をあるパーティションから別のパーティションに移したりするのにコストがかかる
- 良くないクエリだと、全てのパーティションをスキャンしてしまってパフォーマンスが落ちる
- スキーマを変更するのがリスキー

#### シャーディング

- パーティションのホストPCが複数に分散しているような感じ
- レプリカではない、パーティションと同じように分割されている
- じゃあどうやって目的のデータが存在するDBを探すか？
  - コンシステントハッシング
    - ハッシュリングと呼ばれるリング状に、ノードをハッシュ関数で変換した結果を配置する
    - データ(idなど)も同じように変換して、上からプロットする
      - 双方ハッシュ化されるが、どちらも入力は一意なので出力は変わらない
    - 時計周りに考えて、自身が担当する部分をそのノードで管理する
    - データ数がある程度大きくないと、データが偏る可能性があるので注意
    - ノード増減時の再マッピングは注意が必要

![コンシステントハッシング](https://cdn-ak.f.st-hatena.com/images/fotolife/q/quoll00/20211026/20211026054530.png)

- 実際実装するときは、外部のライブラリを使うといいかも
- 例では、あるデータに対してハッシュ化して、それを列として格納していた

- 利点
  - 可用性が高い
    - データ
    - メモリ
  - セキュリティ
    - アクセス対象のDBが限られる
  - インデックスサイズが小さくなる

- 欠点
  - クライアントが分散していることを認知する
  - トランザクション
    - Atomicity
  - ロールバック
  - 結合
  - キーとなる値を入れる必要がある？

- どのようなときにシャーディングを使うか？
  - 多数のユーザーによるアクセスなどで、メインコンピュータに負荷があるとき
  - レプリケーションが使えるのでは？
  - コンフリクトについて問題がある？
  - シャーディングはコストが高いので、どれもだめだったら使うぐらい？
  - パーティショニングはAtomicityをサポートできるが、シャーディングはできない
  - シャーディングを再構成するのもしんどい
  - 本当にこれを犠牲にして実現したいサービスか?
    - Youtubeなど

### 排他制御

- 排他ロックと共有ロック
- ロックを取得するに以下の方法がある
  - ロック読み取りをする(`SELECT ... FOR UPDATE`や`SELECT ... FOR SHARE`)
  - `UPDATE`や`DELETE`
- 排他ロックは他からのロック読み取りができなくなる
  - データを順番に更新することが目的
  - 一つのトランザクションしか取得できない
- 共有ロックはデータを読み取っていることを示すためのロック
  - 複数のトランザクションから取得できる

#### 共有ロック

- 読み取る際に、読み取る間は値を更新しないでくれというロック(読み取りロック)
- 他のトランザクションから参照はできる
- 更新は不可
- 今は行ロックを考える

#### 更新ロック

- `UPDATE`をすると更新ロックが取られたあとに排他ロックへ昇格する
- 更新ロック自体は共有ロックと同じレベルのもの

#### 排他ロック

- 他のトランザクションからは参照も更新もできない
- 占有ロック
- つまり、排他ロックを取ると他のロックは取得できない
- 今は行ロックを考える

#### インテントロック

- レコードに排他ロックを掛ける場合、その上位階層であるページとテーブルに対してインテントロックが自動でかけられる
  - インテントロック自体は弱いロック
  - 目的はほかのトランザクションが、その一連の階層に対してロックがかけられないことが一目でわかるため

#### ロックの取り方

- めっちゃいろんな粒度があるらしい
- よく聞くのは行ロックやテーブルロック
- SQL Serverでは、発行するクエリによって自動で必要なロックを掛けてくれる
  - 実は何らかのロックは必ず取られている
    - `SELECT`は共有ロック
    ｰ `INSERT/UPDATE/DELETE`は排他ロック
- noblockとすると、スキーマ安定度ロックというものが取られて、これは排他ロックされていても読み取ることができる
  - ただコミットされていないデータを読み取ることになるので、ダーティリードとなる可能性がある

- 上位の階層のリソースにロックが掛かっていると、下位のリソースに対してロックを掛けられない
  - テーブルロックが取られているテーブルに対して行ロックはできない
- 同じ階層だが別のリソースに対してはロックを掛けることができる
- REPEATABLE READはテーブルロック+共有ロック？

- プライマリキーでとある行を指定して更新するときは行ロック
- 範囲選択すると範囲ロック
- 上記の境界をロックすることもあるらしい

##### ロックの保持期間

- 明示的にトランザクションを開始しているかどうかで変わる

- 明示的なトランザクションを行わない場合
  - 共有ロックや排他ロックの有効期間は、そのクエリが実行されている間のみ
- 明示的にトランザクションを行う場合
  - 排他ロックは、一回取るとトランザクション終了時まで維持される

- つまり、できる限りトランザクションの時間は短い方が良い

- 例えばテーブルの全レコードを更新するとき、1レコードずつ排他ロックを掛けるよりも、テーブルに1つだけ排他ロックを掛けるほうが効率がいい
  - DBMSが自動的にロックレベルをテーブルに昇格する場合がある(ロックエスカレーション)
  - ただ、エスカレーション先は必ずテーブルのみで、それ以上先は行かない

#### デッドロック

- 排他ロックを使っていると、デッドロックが起こる可能性がある
- 共有ロックを取得したデータを更新してしまう
- トランザクションの順序が逆になる
- 外部キー・View・トリガーもロックを考えるときに考慮するべき
  - 同じリソースを触るときは注意が必要

- 楽観的ロック
  - データ取得時にロックを掛けず、アプリ側で考慮を行う

- 悲観的ロック
  - DBMSのロックを使用する

##### サイクルデッドロック

1. トランザクション1がA→Bの順でテーブルを更新する
2. トランザクション2がB→Aの順でテーブルを更新する

- それぞれがそれぞれの更新待になる
- アクセス順が異なることで発生する

![サイクルデッドロック](https://i.gyazo.com/f57ff22ea2d96a4dcaae868d1d0883ad.png)

##### ギャップデッドロック

- クエリにマッチする行が0行だった場合、ネクストキーロックが絡んでくる
  - ファントムリードを解するためのロックの仕組み
- この場合、ネクストキーロックとして-∞～+∞に実質的な共有ロックがかかる
- 該当の例えばユーザーの行ロックを予め取得しておくと良いらしい

![ギャップロック](https://storage.googleapis.com/zenn-user-upload/r6h0oexj6bafxrg2xrys8ughmj9c)

##### 変換デッドロック

- SQL Server特有のもの
  - REPEATABLE READ以上だと、共有ロックがトランザクション終了時まで継続する
  - その後に`UPDATE`すると、更新ロックが取られてその後に昇格する排他ロックが要因となって発生する
- DBのアクセス順序を守って`SELECT`→`UPDATE`してもなってしまう
- トランザクション1とトランザクション2が共有ロックを取得した後、それぞれで`UPDATE`(排他ロック)を取得しようとすると起こる
- これは共有ロック同士であれば取得可能なために起こるので、最初の共有ロックが発生する部分を排他ロックとかにする

![変換デッドロック](https://i.gyazo.com/81794a0002c8383de7b657a4ee303337.png)

##### その他デッドロック

- 不必要に大きな範囲で(テーブルとか)ロックを取ってしまったりする

##### Two-phase Locking

- ダブルブッキング問題
- デッドロックが起こらなくても、同時進行でクエリが発行されると後勝ちになってしまう
- 最初の条件チェックで`FOR UPDATE`とすれば良い
- ただし、明示的にロックを掛けなくても、DBMSの内部的なロックと適切な条件式を与えれば回避できたりする

#### 行バージョン方式

- 通常は`SELECT`時にもロックが取られるが、それによる同時実行性の低下を防ぐためにロックを取らないけど競合が発生しないような仕組みがある(MVCC)
  - SQL Serverの場合
- それを実現するのが行バージョン
  - コミット済みのデータを読むのでwith(nolock)とは異なる

- SQL Serverの行バージョン管理は以下の2種類
  - スナップショット分離レベル
    - 明示的にやったときしかこうならない
  - READ COMITTED SNAPSHOT 分離レベル
    - 通常のREAD COMITTEDは検索時に共有ロックを取得するが、そのときに行バージョンを使用した検索となり、ロックを取得しなくなる
    - これをやると、通常のREAD COMITTEDトランザクション分離レベルを使用しているセッションのすべての動作がこれになる

- 機能を有効化すると、変更されたレコードに14バイトの情報が追加される
  - 14バイトのオーバーヘッドが発生して、ページ分割の頻度が増えるかも
- データの変更が行われるとtempdbに変更前のデータが格納される
  - 「行バージョン管理では、行が更新されるたびに、SQL Server データベース エンジンは tempdb 内の元の行のコピーを保存し、行にトランザクション シーケンス番号を追加します。」
- tempdbに格納されている変更前のデータがメモリ上にキャッシュされる

- tempdbに格納された行のバージョン管理情報は定期的にクリーンアップされる
- ただし、あるトランザクションが終わらないと、それ以降に完了したトランザクションのバージョン情報がtempdbに残り続けるらしい

#### ページングを考慮したデータの取得

- `OFFSET`を使うのはやめたほうがいいらしい(ロックエスカレーション？)
- `LIMIT`は良いみたい

#### コネクションプール

- 通常のコネクションは接続を確立して、破棄する流れを踏むので大量アクセス時などはパフォーマンが落ちる
- コネクションプールのものを使用することで上記のコストを削減できる
- ただし使ったコレクションのトランザクション分離レベルは維持される
  - SERIALIZABLEにしたらプールに戻す前に戻さないと、意図しないデッドロックの元になりそう

### レプリケーション

- 障害から守る、冗長化

- マスターバックアップ・レプリケーション
  - マスターノードが存在し、そこに書き込む(書き込みはこのノードだけ)
  - マスターノードから子どものノードへ変更を伝搬する
  - コンフリクトが発生しない
  - 実装が簡単

- マルチマスターレプリケーション
  - コンフリクトの対応が必要
  - 実装も難しい

- マスターノードの変更の伝搬
  - 同期的
    - マスターノードへの書き込みは、バックアップが完了するまでロックされる
    - 整合性は常に保たれる
  - 非同期的
    - ロックはマスターへの書き込み中のときだけ
    - 結果整合性？

- メリット
  - 水平スケーリング
  - 地域ごとのDB?
- デメリット
  - 結果整合性
  - 同期的に書く場合は遅い
  - マルチマスターの場合は実装が複雑

### Twitterを例に

- 非機能要件
  - サーバーとの通信に失敗した場合のためにローカルDB
  - オートリトライ

- スケーリング
  - クライアントサイドでは、接続先サーバーを複数持つなど
  - ロードバランサー
    - 暗号化のために証明書
    - リバースプロキシ
    - H2とは？

- 機能の設計
  - プロファイルテーブル
  - FFの管理
    - めちゃくちゃデカくなることが容易に想定される
    - インデックス
      - 経験的にイケるらしい
      - `INSERT`は早い
        - API制限やボット対策などで、メチャクチャな負荷は制限されている
      - ただし、インデックスを再作成するコストがかかる
    - 取得はREST APIだと怪しいらしい
      - キャッシュを見るから、最新の状態を取得できない？？

- このレベルのサービスになってくると、テーブルが巨大になってどうしても処理に時間がかかる物が出てくる
  - DB設計でなんとかできない範囲はUXデザインで考慮するのも手
  - 例えばユーザーのプロファイル画面
  - 先に簡単に取得できるvioや写真を表示する
  - 処理に時間がかかるFF数とかは非同期的に取得するなど

- 外部からはシステムの内部構造が見えない、予測可能であることは好ましくない
- SQLインジェクション
- そのテーブルの性質として、読み書きのどちらが多いか
- Unbounded Queryはやめよう

## DBMS

- いくつかのDBMSはDBをスイッチできる

- DB
  - インデックスを工夫しているものだったり
  - トランザクションをサポートしてないものだったり(MyISAM)
  - ロックがテーブル単位だったり(MyISAM、SQLite)
  - SQLiteはB-Tree
    - Postgresに似たようなシンタックス
  - Level DBは読み書きがめっちゃ早いけど、`UPDATE`はよろしく無いらしい(SSDの寿命？)
    - Log structured merge tree
  - RocksDBはB-treeを使ってないのに高速らしい

## カーソル

- 例えば`SELECT`を1レコードずつ取得できる
- 使い方
  - 1行ずつ処理したいクエリに対して`DECLARE CURSOR`と宣言する
  - `FETCH`すると1行ずつ取得される

- 利点
  - メモリの節約
  - ストリーミング？
  - キャンセルが楽
- 欠点
  - ステートフル
    - 他のトランザクションの処理の影響を受ける
  - トランザクションが長くなる

- クライアントサイドの方がサーバーサイドのカーソルよりも早い
  - 多分全部持ってきてからカーソルするか、サーバーサイドでカーソルするか
  - データ転送の問題でサーバーサイドのほうが時間はかかる
  - 一方で、データのリアルタイム性はある？
    - オプションによって変化する
      - リアルタイム性をもたせることもできる
      - tempdbに結果を保存してから処理することもある

## NoSQL

- Not Only SQL
  - RDBMS以外のDBMSの総称
    - キーバリュー型
    - ドキュメント指向型
    - 列指向

- MongoDB
  - ドキュメント指向型
    - BSON(バイナリJSON)
    - サイズが大きいときは圧縮する
  - データ構造は自由(レコードに当たるもの)
    - それらの集合はコレクションと呼ばれる(テーブルに当たるもの)
  - クエリはJavascript
  - 高度なトランザクション処理ができない
    - グローバルでロックされる
  - 高度な結合処理ができない
  - コレクションを作成すると主キーが作成され、B+Treeインデックスが作成される

- RDBMSはJSONのスキーマ定義をすることが苦手
- フロントとのやり取りなど、JSONを利用する場面が増えてきた

- オリジナルのMongoDB
  - どんなデータでも入れられるが、データ内容を変えるとサイズが変わるため、オフセット情報が変わってしまう(スキャンに影響)
  - グローバルロック

- Wire Tiger(4.2~5.2)
  - 新しいストレージエンジン
  - 上記の問題が解決されている
  - セカンダリインデックスのように、セカンダリインデックス→プライマリインデックスと2段階探索になる

- Wire Tiger(5.3~)
  - リーフノードにデータが必ずいる
    - ユーザーが定義するセカンダリインデックスは12byte??
  - インデックスサイズが容量を圧迫するかも

- キャッシュは最終手段であるべき
  - 他のチューニングに問題がないかを確認する
  - 断片化

## セキュリティ

- SSL/TLS
  - トランスポート層
- 昔はユーザーとサーバーが近かったが、クラウドに変わるにつれて考える必要が出てきた

- サーバーに証明書を置く
  - opensslなど

- wireshark:パケットアナライザツール

- ログイン時はユーザー名とパスワードのどちらが間違えているかは教えてはいけない

- MongoDBはコネクションを立てて切断するだけで、4往復している？

- 長いクエリを送ったらどうなるか？
  - 意外とエラーにはならない(数MB)が、パケット的にもやめたほうが良いです
  - あまりに大きいとサーバーがクラッシュする
  - 攻撃のポイントとなってしまう

- XXS:入力フィールドなどを通じてスクリプトを中に注入する

- 発行するクエリごとに、接続ユーザーを変更する
  - `SELECT`するやつだったらreadonlyだけ
  - `CREATE`するやつだったらこいつだけに`CREATE`権限を与えるとか
  - シーケンス？

- バックエンドのエラー情報もなるべく隠蔽する

## ホモモーフィック暗号化

- 暗号化されたデータ上で演算を実行できる暗号化形式
  - 複合化の必要がない
- 暗号化のアイデアは、同じキーで暗号化と復号化を行う
- ただし、クエリは常に平文で発行する必要があるし、分析などもそう
- めっちゃ遅いらしいけど
  - インデックスと最適化は可能らしい？

## Q&A/Discussion

- ページ内にデータがどのように分布しているかは、DBMSはわからない
  - 可変長データがあると分からない
  - インデックスはページごとに取得される

- 頻繁に検索される非キーの列をインデックスに含めるのはよくやることらしい

- selializableと`SELECT FOR UPDATE`の違い
  - 後者は平行性が制限されるらしい(時間がかかる)
    - 悲観的ロック
  - ただ前者は競合すると失敗する可能性がある
    - 楽観的ロック

- コネクションプールを使用する意味
  - 同時実行性
  - 同一のコネクションをいろんなユーザーが使いまわしていると、並行して実行されるクエリの応答が誤ったクライアントに届く場合がある

- readonlyなトランザクション
  - クライアントの保護
  - ある場合にパフォーマンスが向上する？

- uuid
  - 一意性はあるが、ランダム性が強すぎてインデックスに向かない
  - サイズが大きいので、1ページに入るレコードが少なくなり、検索性も落ちる

- fill factor
  - 1ページの中でどれだけデータが詰まっているか
  - ページが変わるとインデックスが再生成される？

- でかい複合インデックスは作るべきか？
  - 当然複合インデックスのサイズはデカくなる
  - どれかの列が更新されてもインデックスを更新する必要がある
    - I/Oが増える

- 同じようなクエリでも、ゴーストレコードなどによって実行時間が変わってくる
  - あと統計情報

- DurabilityとPersistence
  - Durabilityは値を**データベースに書き込んだ場合**、データがディスクに永久に保存され、DBがクラッシュまたは再起動した場合でも利用可能であることを指す
  - PersistenceはDBがデータをディスクに保存し続けるための機能と能力
    - メモリ上に保存されているものなど

- トランザクション中に削除したあとの後始末としてゴーストレコードを削除したほうが良い？

- WAL(Write-Ahead Logging)
  - DBMSにおいてトランザクションの耐久性とデータ日整合性を確保するための概念
  - コミット前にトランザクションの変更をログに記録している
    - DBがクラッシュしてもトランザクションの変更が失われない
  - ディスクへの書き込みは少ない方が良い
  - undo log
    - ロールバック用
    - トランザクションが長いと、こいつが多く溜まってしまう
    - ちなみにredo logはコマンドのみを保存しているだけだからコストは少ない
      - ロールフォワード用

- `SELECT COUNT(*)`はテーブルサイズが増えると劇的に遅くなる？
  - `UPDATE`や`DELETE`すると、ゴーストレコードが溜まってクエリが遅くなる
  - よくわからんが、DBが予想する実行プランよりも、実際に取得する行数が多くなることがあるのか？

- ULID:ソート可能なUUID？
  - タイムスタンプを含む
  - 一意性は最強だが、インデックスを含むサイズが非常に問題

- TCP
  - 対話式？
  - 信頼性が高い
  - パケットロスが起こった場合は再送を要求したりする
- UDP
  - シーケンス番号や識別子が存在しない
  - 信頼性が低いが、高速
  - パケットロスがあっても気にしない
- QUIC
  - 理論的にはTCPとUDPのいいとこ取り

- 分散トランザクション
  - マイクロサービス
  - 複数のDBMSに別のトランザクションをしに行くが、論理的には1つのトランザクションとして扱いたい
  - 原子時計?
  - フェーズコミット

- Postgreはすべてのインデックスがセカンダリインデックス
  - すべてのインデックスがデータを直接指す
  - データを削除/更新するとすべてのインデックスを更新しに行く
  - Readはめっちゃ早い
- MySQLではすべてのインデックスはプライマリキーを指す、データにアクセスするのはプライマリキーだけ
  - データを削除/更新しても、更新はプライマリキーだけ
  - プライマリキーを頻繁に更新するのは注意が必要？

- ハッシュテーブル
  - キーと値の組をセットで管理するデータ構造
  - 連想配列などを実現する仕組み
  - 配列...通常時は読み出しなどは楽だが(メモリ上に順番に並んでいるため)、値の追加削除を行うと再構成する必要があってコストが高い
  - リンクリスト...追加は末尾に追加するだけなので良いが、読み出しは1つずつなので時間がかかる
  - ハッシュテーブル...つかするときハッシュ関数を回してキーからアドレスを取得し、呼び出す際はキーさえあればアドレスもわかるので比較的高速
- てもハッシュテーブルを作るときは重複しないようにしなくてはいけないのでコストが高い
- 問題点
  - メモリ管理
  - ビルドするときのコスト
  - キーの追加と削除
    - 既存項目と衝突していないか？
    - シャーディングとかやってるとやばそう
- この問題点を解決できるのがコンシステントハッシュの考え方
  - ハッシュリングの優れている部分は、新しいサーバーを追加したときに、データの再構築をする必要がある対象のサーバーは次の1つだけ
  - サーバーを削除した場合も、次のサーバーに移動するだけ
    - その再分配が未だに問題だが...

- なぜUberはPostgresからMySQLへ乗り換えたか

- `NULL`はパフォーマンスを向上させるか？
  - 0でもなんでも32bitであれば、そのカラムの値はメモリを占拠する
    - 1ページに入れられるデータ量が多くなるのでI/Oが少なくなる
      - インデックスの効きがよくなる？
  - `NULL`を扱うときのSQL文の違い
  - インデックス？DBMSによるらしい
  - 外部結合のときに`NULL`とか必要だね

- SQL Serverにおいて、行ロックのコストは高い
  - メモリ不足になりやすいらしい
  - Postgresはその部分のマネジメントがうまいらしい

- SQL Serveは可用性が高いらしい
  - MVCCはサポートされていない
- Postgresは非リレーショナルも対応しているみたい
  - MVCCにより、デッドロックの可能性が低い

## 参考

- [分散システムの一貫性に関する動向について](https://techblog.yahoo.co.jp/architecture/2015-04-ditributed-consistency/)
- [ビットマップインデックスの仕組み](https://qiita.com/gohandesuyo/items/b3a684157b2eefc69a79)
- [VACUUMでPostgreSQLのゴミデータをお掃除！](https://tech-blog.rakus.co.jp/entry/20221227/vacuum#PostgreSQL%E3%81%AE%E3%83%AC%E3%82%B3%E3%83%BC%E3%83%89%E6%9B%B4%E6%96%B0%E5%89%8A%E9%99%A4%E3%81%AE%E3%81%97%E3%81%8F%E3%81%BF%E3%81%A8%E5%95%8F%E9%A1%8C%E7%82%B9)
- [トランザクションとは【ACID vs BASE】](https://rakusui.org/acid/)
- [データベースのロックの基礎からデッドロックまで](https://zenn.dev/gibjapan/articles/1d8dfb7520dabc)
- [SQL Serverのロックについて出来る限り分かりやすく解説](https://qiita.com/maaaaaaaa/items/38fd95b142b07acf7700)
- [SQL Server / SQL Database の行のバージョン管理の基本動作](https://blog.engineer-memo.com/2021/03/24/sql-server-sql-database-%E3%81%AE%E8%A1%8C%E3%81%AE%E3%83%90%E3%83%BC%E3%82%B8%E3%83%A7%E3%83%B3%E7%AE%A1%E7%90%86%E3%81%AE%E5%9F%BA%E6%9C%AC%E5%8B%95%E4%BD%9C/)
- [トランザクションのロックおよび行のバージョン管理ガイド](https://learn.microsoft.com/ja-jp/sql/relational-databases/sql-server-transaction-locking-and-row-versioning-guide?view=sql-server-ver15#locking-and-row-versioning-basics)
- [デッドロック ガイド](https://learn.microsoft.com/ja-jp/sql/relational-databases/sql-server-deadlocks-guide?view=sql-server-ver15)
- [MySQLで発生し得る思わぬデッドロックと対応方法](https://zenn.dev/shuntagami/articles/ea44a20911b817)
- [SQL Serverのロック管理](https://atmarkit.itmedia.co.jp/fdotnet/entwebapp/entwebapp09/entwebapp09_01.html)
- [第 3 章 トランザクション分離レベルの選択とデッドロックの問題～ SQL Server 2000 における Web アプリケーション開発 ～](https://learn.microsoft.com/ja-jp/previous-versions/cc707374(v=msdn.10)?redirectedfrom=MSDN)
- [PostgreSQL と SQL Server の主な違い](https://cloud.google.com/learn/postgresql-vs-sql?hl=ja)
- [コンシステントハッシング](https://qiita.com/hharu/items/eca1338c2c0effd0a15d)
- [増永教授のDB特論⑨「NULL」](https://www.sraoss.co.jp/tech-blog/db-special-lecture/masunaga-db-special-lecture-9/)